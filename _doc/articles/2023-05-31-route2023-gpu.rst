.. _l-feuille-de-route-2023-3A:

2023-05-31: Feuille de route 2022-2023 (3A)
===========================================

Plan
++++

Les cours et séances se déroulent sur 6 séances de 3h au second semeste.

Intervenants
++++++++++++

Xavier Dupré, Matthieu Durut.

Notes
+++++

Liens, notebooks prévus pour les séances pratiques.

Séance 1
^^^^^^^^

1.

* hardware
* ordinateur
* mémoire partagée
* ordre de grandeur vitesse CPU, communication

2.

* algorithmes répartis
* multithread
* `race condition <https://en.wikipedia.org/wiki/Race_condition>`_
* verrou

Séance 2
^^^^^^^^

Séance pratique sur CPU.

**Plan : parallélisation avec CPU**

1.

* Setup SSP Cloud, présentation d'un package, C++
* Outils de développement : :epkg:`cmake`, :epkg:`git`, :epkg:`pull request`
* Python : :epkg:`setup.py`, :epkg:`sphinx`, :epkg:`pybind11`, :epkg:`cython`
* style : :epkg:`black`, :epkg:`ruff`

2.

* Somme des éléments d'une matrice
* en ligne, en colonne, notion de cache, :epkg:`std::vector`, numpy array, benchmark
* éléments de C++, :epkg:`pybind11`, :epkg:`cython`
* :epkg:`AVX`
* parallélisation avec des :epkg:`threads`, :epkg:`processus`

3.

* Exercice : somme de deux vecteurs
* parallélisation d'une multiplication de matrices
* applications aux random forest

4.

* :epkg:`blas`, :epkg:`lapack`, :epkg:`Eigen`, :epkg:`blis`
* :epkg:`Triton`, :epkg:`TVM`, :epkg:`AITemplate`,
  `treelite <https://treelite.readthedocs.io/en/latest/>`_

**Instructions pour démarrer**

* Aller sur la plate-forme `SSPCloud de l'ENSAE <https://datalab.sspcloud.fr/home>`_.
* Se connecter avec son adresse ENSAE
* Ouvrir une instance :epkg:`vscode-python`

Il ensuite exécuter les instuctions suivantes en ligne de commande.

:: 

    git clone https://github.com/sdpython/onnx-extended.git
    cd onnx-extended
    python setup.py build_ext --inplace

Si ça ne marche, installer cmake: ``conda install cmake``.
Puis :

::

    export PYTHONPATH=<this folder>
    python _doc/examples/plot_bench_cpu_vector_sum.py

Séance 3
^^^^^^^^

Séance pratique sur Spark.

1.

* Présentation de spark, objectif
* HDFS, premiers pas avec Spark, `java <https://en.wikipedia.org/wiki/Java_(programming_language)>`_
* Notion de spark dataframes
* `parquet <https://parquet.apache.org/>`_

2.

* Lien avec SQL, group by, join
* Importance de collect
* `Spark SQL <https://spark.apache.org/sql/>`_
* Lecture, écriture

3.

* Distribution : :ref:`Hash et distribution <nbl-practice-expose-hash_distribution>`
* Notion de skewed datasets
* group by + count, group by + mediane
* Exercice

On veut calculer pour chaque français le nombre de points de vente alimentaires (~44.000)
situé à moins de trois kilomètres du domicile. Comment faire ? On dispose que deux jeux
de données :

* la géolocalisation des points de vente alimentaires et leur taille
* la géolocalisation des français (toutes les adresses connues dans les pages blanches)

4.

* `mllib <https://spark.apache.org/mllib/>`_
* notion d'algorithmes de streaming, BJKST,
  :ref:`Reservoir Sampling <nbl-practice-mapreduce-reservoir_sampling>`

Séance 4
^^^^^^^^

Séance 5
^^^^^^^^

CUDA

Les séances pratiques s'appuient sur le package :epkg:`onnx-extended`.

::

    git clone https://github.com/sdpython/onnx-extended.git
    cd onnx-extended
    python setup.py build_ext --inplace

1.

* CUDA, threads, blocks, parallélisation
* gestion de la mémoire
* addition de deux vecteurs
* code C++, template, macro
* gcc, nvcc

2.

* pointeurs
* somme des éléments d'un vecteur, réduction
* synthreads
* GPU / CPU, __inline__, __globals__, `<<< >>>`

3.

* Profiling
* :epkg:`DLPack`
* device
* A100, H100
* float32, float16, float8
* multiple nvidia on the same machine

4.

* torch
* `td3a_cpp_deep <https://github.com/sdpython/td3a_cpp_deep>`_

Séance 6
^^^^^^^^
