.. _l-feuille-de-route-2024-3A:

2024-05-31: Feuille de route 2023-2024 (3A)
===========================================

* Main Web Site : `https://sdpython.github.io/ <https://sdpython.github.io/>`_
* Material : `https://sdpython.github.io/doc/teachcompute/dev/ <https://sdpython.github.io/doc/teachcompute/dev/>`_

Plan
++++

Les cours et séances se déroulent sur 6 séances de 3h au second semeste.

Intervenants
++++++++++++

Xavier Dupré, Matthieu Durut.

Evaluation
++++++++++

Optimize a machine learning model by fusing operations.

* `alpindale/Llama-2-7b-ONNX <https://huggingface.co/alpindale/Llama-2-7b-ONNX>`_

::

    pip install -U huggingface_hub
    huggingface-cli download alpindale/Llama-2-7b-ONNX --repo-type model --cache-dir cache --local-dir . --local-dir-use-symlinks False

Or:

::

    python -m experimental_experiment.torch_bench.export_model --model llama --mixed 1 --exporter script --config small --num_hidden_layer 2

.. image:: images/netron.png

One part of the llama model:

.. image:: images/llama.png

The goal is not to optimize the whole model
but to optimize locally one execution path,
in CUDA or CPU.

Notes
+++++

Liens, notebooks prévus pour les séances pratiques.

Séance 1 - 10/04
^^^^^^^^^^^^^^^^

Séance pratique sur CPU.

1. Environnement

* Setup SSP Cloud, présentation d'un package, C++
* Outils de développement : :epkg:`cmake`, :epkg:`git`, :epkg:`pull request`
* Python : :epkg:`setup.py`, :epkg:`sphinx`, :epkg:`pybind11`, :epkg:`cython`
* style : :epkg:`black`, :epkg:`ruff`
* :epkg:`github` et intégration continue
* Copy/Pasting is your friend.

2. Examples

* :ref:`l-parallelization-vector-sum`
* :ref:`l-parallelization-dot-product`
* :ref:`l-compare-filtering-implementation`
* :ref:`l-parallelization-processes`

3. Concepts

* parallelization, conflicts
* thread / process
* :epkg:`AVX`
* branching, cache L1, L2, L3
* C++ syntax

4. Technics

* :epkg:`C++`
* :epkg:`Python C API`
* :epkg:`pybind11`, :epkg:`cython`
* :epkg:`blas`, :epkg:`lapack`, :epkg:`Eigen`, :epkg:`blis`

**Instructions pour démarrer**

* Aller sur la plate-forme `SSPCloud de l'ENSAE <https://datalab.sspcloud.fr/home>`_.
* Se connecter avec son adresse ENSAE
* Ouvrir une instance :epkg:`vscode-python`

Il ensuite exécuter les instuctions suivantes en ligne de commande.

:: 

    git clone https://github.com/sdpython/teachcompute.git
    cd teachcompute
    python setup.py build_ext --inplace

Si ça ne marche, installer cmake: ``conda install cmake``.
Puis :

::

    export PYTHONPATH=<this folder>
    python _doc/examples/plot_bench_cpu_vector_sum.py

Séance 2 - 12/04
^^^^^^^^^^^^^^^^

1.

* hardware
* ordinateur
* mémoire partagée
* ordre de grandeur vitesse CPU, communication
* caches

2.

* algorithmes répartis
* multithread
* `race condition <https://en.wikipedia.org/wiki/Race_condition>`_
* verrou

Séance 3 - 17/04
^^^^^^^^^^^^^^^^

CUDA

Les séances pratiques s'appuient sur le package :epkg:`teachcompute`.

::

    git clone https://github.com/sdpython/teachcompute.git
    cd teachcompute
    python setup.py build_ext --inplace

1.

* CUDA, threads, blocks, parallélisation
* gestion de la mémoire, CPU, CUDA

2. addition de deux vecteurs

* :ref:`l-example-cuda-vector-addition`
* `cuda_example.cu L19 <https://github.com/sdpython/teachcompute/blob/main/teachcompute/validation/cuda/cuda_example.cu#L19>`_
* code C++, template, macro
* gcc, nvcc
* extension .c, extension .cu
* ``__device__``, ``__globals__``, ``__inline__``, `<<< >>>`
* profiling

2. somme d'un vecteur

* :ref:`l-example-cuda-vector-sum`
* `cuda_example.cu L61 <https://github.com/sdpython/teachcompute/blob/main/teachcompute/validation/cuda/cuda_example.cu#L61>`_
* `cuda_example_reduce.cu <https://github.com/sdpython/teachcompute/blob/main/teachcompute/validation/cuda/cuda_example_reduce.cu>`_
* somme des éléments d'un vecteur, réduction
* synthreads
* mémoire partagée, notion de cache

3. ScatterND

* :ref:``
* notion de Stream

4. extension torch

* torch
* `torch_extensions <https://github.com/sdpython/teachcompute/blob/main/teachcompute/torch_extensions>`_

5.

* :epkg:`DLPack`
* device
* A100, H100
* float32, float16, float8
* multiple nvidia on the same machine

Séance 4 - 19/04
^^^^^^^^^^^^^^^^

... en préparation ...

Séance 5 - 26/04
^^^^^^^^^^^^^^^^

... en préparation ...

Séance 6 - 03/05
^^^^^^^^^^^^^^^^

... en préparation ...

deeplearning, llm, torch, cuda, triton...

* :epkg:`Triton`, :epkg:`TVM`, :epkg:`AITemplate`,
  `treelite <https://treelite.readthedocs.io/en/latest/>`_
